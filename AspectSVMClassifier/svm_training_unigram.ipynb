{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import os\n",
    "from sklearn import svm\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import  PorterStemmer\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_map={'Aspect1':1 ,'Aspect2':2 ,'Aspect3':3 ,'Aspect4':4 ,'Aspect5':5,'Aspect6':6 ,'Aspect7':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():  \n",
    "    dataset=[]\n",
    "    for root, dirs, files in os.walk('../Dataset'):\n",
    "        for directory in dirs:\n",
    "            for root_f, dirs_f, files_f in os.walk(os.path.join(root,directory)):\n",
    "                for each_file in files_f:\n",
    "                    with open(os.path.join(root,directory)+'/'+each_file) as f:\n",
    "                        data_temp=json.load(f)    \n",
    "                    dataset+=[(sentence,label_map[directory]) for sentence in data_temp]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_unigram(data):\n",
    "    dataset=[]\n",
    "    dataset+=[([items for items in sentence.split()],polarity) for sentence,polarity in data]    \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words(x):    #returns all the words in the  data set\n",
    "    vocab = []\n",
    "    for sentence,polarity in x:  \n",
    "        vocab.extend(sentence.split())\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#execution\n",
    "labeled_data=load_dataset()    #loading labeled sentences\n",
    "random.shuffle(labeled_data)\n",
    "with open('../NaiveBayes/vocab_unigram') as f:\n",
    "    vocab=json.load(f)\n",
    "#labeled_data=to_unigram(labeled_data)    #converting to unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([u'typic', u'day', u'work', u'learn', u'manag', u'co', u'worker', u'hardest', u'part', u'job', u'enjoy', u'part', u'job'], 1), ([u'although', u'abl', u'get', u'manag', u'skill', u'job', u'made', u'hard', u'balanc', u'work'], 1), ([u'great', u'experi', u'compani', u'past', u'year'], 6), ([u'work', u'learn', u'work'], 1), ([u'someon', u'look'], 7), ([u'realli', u'love', u'creat', u'beauti', u'softwar'], 7), ([u'meet', u'certain', u'criterion', u'time', u'manag', u'effici'], 4), ([u'job', u'learn', u'use', u'slip', u'leader'], 1), ([u'gener', u'construct', u'environ'], 6), ([u'work', u'life', u'balanc', u'good'], 4)]\n"
     ]
    }
   ],
   "source": [
    "#bigrams\n",
    "print labeled_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201378\n"
     ]
    }
   ],
   "source": [
    "print len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6544\n",
      "[u'foul', u'interchang', u'four', u'payoff', u'authorit', u'scold', u'lore', u'lord', u'digit', u'pigment', u'yellow', u'delv', u'fur', u'disturb', u'scholar', u'wooden', u'showca', u'habea', u'charter', u'erron', u'nigh', u'rustl', u'miller', u'histor', u'second', u'sooth', u'tether', u'dialogu', u'ruthless', u'thunder', u'specialist', u'aver', u'intellectu', u'hero', u'avert', u'accu', u'herd', u'gamut', u'china', u'cult', u'deterior', u'militari', u'k', u'pastur', u'fumbl', u'diplomat', u'golden', u'brought', u'sterl', u'stern', u'unit', u'spoke', u'overshadow', u'music', u'telegraph', u'passport', u'strike', u'expiat', u'paperwork', u'relay', u'relax', u'relat', u'notic', u'hurt', u'glass', u'exc', u'holi', u'outskirt', u'midst', u'hold', u'accid', u'blade', u'conceptu', u'sweeter', u'etiquett', u'household', u'centuri', u'cautiou', u'caution', u'want', u'gargantuan', u'shuffl', u'unpaid', u'travel', u'classifi', u'hot', u'hop', u'turk', u'perspect', u'hoy', u'diagram', u'wrong', u'beauti', u'endang', u'warfar', u'revolv', u'dispar', u'someplac', u'wing', u'wind']\n"
     ]
    }
   ],
   "source": [
    "print len(vocab)\n",
    "print vocab[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(dataset):       #features are bag of words. document is a list of words of a sentence \n",
    "    feature_vector=[]\n",
    "    labels=[]\n",
    "    for sentence,label in dataset:\n",
    "        features = {}\n",
    "        labels.append(label)\n",
    "        for word in vocab:\n",
    "            features[word] = 0\n",
    "            if word in sentence:\n",
    "                features[word] = 1\n",
    "        feature_vector.append(features.values())        \n",
    "    return {'feature':feature_vector,'labels':labels}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features=extract_features(labeled_data[:10])\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "corpus=[sentence for sentence,pol in labeled_data]\n",
    "features=vectorizer.fit_transform(corpus)\n",
    "labels=[label for sentence,label in labeled_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.fit(features,labels)\n",
    "with open('svc_unigram_model','w') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen='work life is bore'\n",
    "classifier.classify(extract_features(sen.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 0.585660\n",
      "sli_pos: 0.035267\n",
      "sli_neg: 0.230902\n",
      "neutral: 0.123239\n",
      "pos: 0.024931\n"
     ]
    }
   ],
   "source": [
    "dist = classifier.prob_classify(extract_features(sen.split()))\n",
    "for label in dist.samples():\n",
    "    print(\"%s: %f\" % (label, dist.prob(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 0.585660\n",
      "sli_pos: 0.035267\n",
      "sli_neg: 0.230902\n",
      "neutral: 0.123239\n",
      "pos: 0.024931\n",
      "0.585660041903\n"
     ]
    }
   ],
   "source": [
    "polarity=0\n",
    "for label in dist.samples():\n",
    "    print(\"%s: %f\" % (label, dist.prob(label)))\n",
    "    polarity=max(polarity,dist.prob(label))\n",
    "print polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
