{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import os\n",
    "from sklearn import svm\n",
    "import json\n",
    "from nltk.stem import  PorterStemmer\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_map={'neg':0 ,'sli_neg':1 ,'neutral':2 ,'sli_pos':3 ,'pos':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():  \n",
    "    dataset=[]\n",
    "    for root, dirs, files in os.walk('../Dataset'):\n",
    "        for directory in dirs:\n",
    "            for root_f, dirs_f, files_f in os.walk(os.path.join(root,directory)):\n",
    "                for each_file in files_f:\n",
    "                    with open(os.path.join(root,directory)+'/'+each_file) as f:\n",
    "                        data_temp=json.load(f)    \n",
    "                    dataset+=[(sentence,label_map[each_file]) for sentence in data_temp]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialising porterstemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_unigram(data):\n",
    "    dataset=[]\n",
    "    dataset+=[([items for items in sentence.split()],polarity) for sentence,polarity in data]    \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words(x):    #returns all the words in the  data set\n",
    "    vocab = []\n",
    "    for sentence,polarity in x:  \n",
    "        vocab.extend(sentence.split())\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#execution\n",
    "labeled_data=load_dataset()    #loading labeled sentences\n",
    "random.shuffle(labeled_data)\n",
    "vocab=set(get_words(labeled_data)) #getting words \n",
    "vocab=[ps.stem(word) for word in vocab]   #stemming\n",
    "with open('vocab_unigram','w') as f:\n",
    "    json.dump(vocab,f)\n",
    "labeled_data=to_unigram(labeled_data)    #converting to unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([u'incred', u'smart'], 3), ([u'one', u'skill', u'comput', u'skill'], 2), ([u'awesom', u'compens', u'age', u'start'], 4), ([u'pay', u'match'], 2), ([u'high', u'energi', u'workplac'], 3)]\n"
     ]
    }
   ],
   "source": [
    "#bigrams\n",
    "print labeled_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201378\n"
     ]
    }
   ],
   "source": [
    "print len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6544\n",
      "[u'yellow', u'interchang', u'four', u'payoff', u'authorit', u'scold', u'lore', u'lord', u'digit', u'pigment', u'foul', u'delv', u'fur', u'disturb', u'prize', u'wooden', u'showca', u'habea', u'charter', u'corpora', u'nigh', u'rustl', u'miller', u'histor', u'second', u'sooth', u'tether', u'dialogu', u'ruthless', u'thunder', u'specialist', u'aver', u'intellectu', u'crouch', u'avert', u'swag', u'herd', u'gamut', u'china', u'cult', u'deterior', u'militari', u'k', u'unforgett', u'fumbl', u'diplomat', u'golden', u'brought', u'sterl', u'stern', u'unit', u'spoke', u'overshadow', u'music', u'telegraph', u'passport', u'strike', u'expiat', u'paperwork', u'relay', u'relax', u'relat', u'notic', u'hurt', u'glass', u'exc', u'holi', u'outskirt', u'midst', u'hold', u'accid', u'blade', u'conceptu', u'sweeter', u'etiquett', u'household', u'eczema', u'cautiou', u'caution', u'want', u'gargantuan', u'shuffl', u'unpaid', u'travel', u'classifi', u'hot', u'hop', u'turk', u'perspect', u'hoy', u'diagram', u'wrong', u'beauti', u'endang', u'warfar', u'revolv', u'dispar', u'someplac', u'wing', u'wind']\n"
     ]
    }
   ],
   "source": [
    "print len(vocab)\n",
    "print vocab[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(dataset):       #features are bag of words. document is a list of words of a sentence \n",
    "    feature_vector=[]\n",
    "    labels=[]\n",
    "    for sentence,label in dataset:\n",
    "        features = {}\n",
    "        labels.append(label)\n",
    "        for word in vocab:\n",
    "            features[word] = 0\n",
    "            if word in sentence:\n",
    "                features[word] = 1\n",
    "        feature_vector.append(features.values())        \n",
    "    return {'feature':feature_vector,'labels':labels}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=extract_features(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'incred', u'smart'], 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.fit(features['feature'],features['labels'])\n",
    "with open('svc_unigram_model','w') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen='work life is bore'\n",
    "classifier.classify(extract_features(sen.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 0.585660\n",
      "sli_pos: 0.035267\n",
      "sli_neg: 0.230902\n",
      "neutral: 0.123239\n",
      "pos: 0.024931\n"
     ]
    }
   ],
   "source": [
    "dist = classifier.prob_classify(extract_features(sen.split()))\n",
    "for label in dist.samples():\n",
    "    print(\"%s: %f\" % (label, dist.prob(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 0.585660\n",
      "sli_pos: 0.035267\n",
      "sli_neg: 0.230902\n",
      "neutral: 0.123239\n",
      "pos: 0.024931\n",
      "0.585660041903\n"
     ]
    }
   ],
   "source": [
    "polarity=0\n",
    "for label in dist.samples():\n",
    "    print(\"%s: %f\" % (label, dist.prob(label)))\n",
    "    polarity=max(polarity,dist.prob(label))\n",
    "print polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
