{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from nltk.stem import  PorterStemmer\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map={'neg':0 ,'sli_neg':1 ,'neutral':2 ,'sli_pos':3 ,'pos':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():  \n",
    "    dataset=[]\n",
    "    for root, dirs, files in os.walk('../Dataset_new'):\n",
    "        for directory in dirs:\n",
    "            for root_f, dirs_f, files_f in os.walk(os.path.join(root,directory)):\n",
    "                for each_file in files_f:\n",
    "                    with open(os.path.join(root,directory)+'/'+each_file) as f:\n",
    "                        data_temp=json.load(f)    \n",
    "                    dataset+=[(sentence,each_file) for sentence in data_temp]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_data=load_dataset()    #loading labeled sentences\n",
    "random.shuffle(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tags(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_polarity(word,tag):\n",
    "    #print 'Get Polarity'\n",
    "    #print 'Word : '+str(word)+' Tag : '+str(tag)\n",
    "    synset = swn.senti_synsets(word,tag)\n",
    "    if(len(synset)>0):\n",
    "        pos_pol=synset[0].pos_score()\n",
    "        neg_pol=synset[0].neg_score()\n",
    "        #print str(pos_pol)+' '+str(neg_pol)\n",
    "        #print ' '    \n",
    "        if(pos_pol == neg_pol):\n",
    "            return 0\n",
    "        if(pos_pol>neg_pol):\n",
    "            return pos_pol\n",
    "        else:\n",
    "            return (-neg_pol)\n",
    "    return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(start, end, step):\n",
    "    tmp = start\n",
    "    while(tmp < end):\n",
    "        yield tmp\n",
    "        tmp += step  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(sentence):       \n",
    "    features =Counter()\n",
    "    for i in frange(-1,1.05,0.05):\n",
    "        features[round(i,2)]=0\n",
    "    pos=nltk.pos_tag(sentence.split())\n",
    "    for word,tag in pos:\n",
    "        tag=tags(tag)\n",
    "        polarity=get_polarity(word,tag)\n",
    "        features[round(polarity,2)] += 1\n",
    "    feature_vector=[]                   # feature vector\n",
    "    for i in frange(-1,1.05,0.05):\n",
    "        feature_vector.append(features[round(i,1)])    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1.0: 0,\n",
       "         -0.95: 0,\n",
       "         -0.9: 0,\n",
       "         -0.85: 0,\n",
       "         -0.8: 0,\n",
       "         -0.75: 0,\n",
       "         -0.7: 0,\n",
       "         -0.65: 0,\n",
       "         -0.6: 0,\n",
       "         -0.55: 0,\n",
       "         -0.5: 0,\n",
       "         -0.45: 0,\n",
       "         -0.4: 0,\n",
       "         -0.35: 0,\n",
       "         -0.3: 0,\n",
       "         -0.25: 0,\n",
       "         -0.2: 0,\n",
       "         -0.15: 0,\n",
       "         -0.1: 0,\n",
       "         -0.05: 0,\n",
       "         0.0: 4,\n",
       "         0.05: 0,\n",
       "         0.1: 0,\n",
       "         0.15: 0,\n",
       "         0.2: 0,\n",
       "         0.25: 1,\n",
       "         0.3: 0,\n",
       "         0.35: 0,\n",
       "         0.4: 0,\n",
       "         0.45: 0,\n",
       "         0.5: 0,\n",
       "         0.55: 0,\n",
       "         0.6: 0,\n",
       "         0.65: 0,\n",
       "         0.7: 0,\n",
       "         0.75: 1,\n",
       "         0.8: 0,\n",
       "         0.85: 0,\n",
       "         0.9: 0,\n",
       "         0.95: 0,\n",
       "         1.0: 0})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features('this is a very good company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test = nltk.classify.apply_features(extract_features, labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dividing into training and test data\n",
    "train_set=train_test[:-10000]\n",
    "test_set=train_test[-10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'neutral')\n"
     ]
    }
   ],
   "source": [
    "print train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "with open('senti_naive_bayes_unigram_model','w') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy=nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6083"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label=[]\n",
    "#feature_svm=[]\n",
    "#for feature,polarity in train_set:\n",
    "#    label.append(polarity)\n",
    "#    feature_svm.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "#features=vectorizer.fit_transform(feature_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
