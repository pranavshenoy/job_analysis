{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from nltk.stem import  PorterStemmer\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():  \n",
    "    dataset=[]\n",
    "    for root, dirs, files in os.walk('../Dataset'):\n",
    "        for directory in dirs:\n",
    "            for root_f, dirs_f, files_f in os.walk(os.path.join(root,directory)):\n",
    "                for each_file in files_f:\n",
    "                    with open(os.path.join(root,directory)+'/'+each_file) as f:\n",
    "                        data_temp=json.load(f)    \n",
    "                    dataset+=[(sentence,each_file) for sentence in data_temp]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialising porterstemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_unigram(data):\n",
    "    dataset=[]\n",
    "    dataset+=[([items for items in sentence.split()],polarity) for sentence,polarity in data]    \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words(x):    #returns all the words in the  data set\n",
    "    vocab = []\n",
    "    for sentence,polarity in x:  \n",
    "        vocab.extend(sentence.split())\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#execution\n",
    "labeled_data=load_dataset()    #loading labeled sentences\n",
    "random.shuffle(labeled_data)\n",
    "vocab=set(get_words(labeled_data)) #getting words \n",
    "vocab=[ps.stem(word) for word in vocab]   #stemming\n",
    "labeled_data=to_unigram(labeled_data)    #converting to unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([u'okay', u'work', u'senior', u'level'], 'sli_pos')\n"
     ]
    }
   ],
   "source": [
    "#bigrams\n",
    "print labeled_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201378\n"
     ]
    }
   ],
   "source": [
    "print len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6544\n",
      "[u'foul', u'interchang', u'four', u'payoff', u'authorit', u'scold', u'lore', u'lord', u'digit', u'pigment', u'yellow', u'delv', u'politician', u'disturb', u'prize', u'wooden', u'showca', u'habea', u'charter', u'corpora', u'nigh', u'rustl', u'miller', u'histor', u'second', u'sooth', u'tether', u'dialogu', u'ruthless', u'thunder', u'specialist', u'aver', u'intellectu', u'crouch', u'avert', u'swag', u'herd', u'gamut', u'china', u'cult', u'deterior', u'militari', u'k', u'pastur', u'fumbl', u'golden', u'brought', u'sterl', u'stern', u'unit', u'spoke', u'overshadow', u'music', u'telegraph', u'passport', u'strike', u'expiat', u'paperwork', u'relay', u'relax', u'relat', u'notic', u'hurt', u'glass', u'exc', u'holi', u'outskirt', u'midst', u'hold', u'accid', u'blade', u'conceptu', u'sweeter', u'etiquett', u'household', u'virtu', u'cautiou', u'caution', u'want', u'gargantuan', u'shuffl', u'unpaid', u'travel', u'cutback', u'hot', u'hop', u'turk', u'perspect', u'hoy', u'diagram', u'wrong', u'beauti', u'endang', u'warfar', u'revolv', u'dispar', u'someplac', u'wing', u'wind', u'feedback']\n"
     ]
    }
   ],
   "source": [
    "print len(vocab)\n",
    "print vocab[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(document):       #features are bag of words. document is a list of words of a sentence \n",
    "    features = {}\n",
    "    for word in vocab:\n",
    "        features['contains(%s)' % word] = (word in document)\n",
    "    return features        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test = nltk.classify.apply_features(extract_features, labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dividing into training and test data\n",
    "train_set=train_test[:-10000]\n",
    "test_set=train_test[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(horribl) = True              neg : pos    =   1957.1 : 1.0\n",
      "       contains(terribl) = True              neg : neutra =   1565.5 : 1.0\n",
      "          contains(bore) = True              neg : pos    =   1428.4 : 1.0\n",
      "           contains(bad) = True              neg : pos    =   1254.9 : 1.0\n",
      "      contains(unfortun) = True              neg : pos    =    657.3 : 1.0\n",
      "          contains(hard) = True           sli_ne : pos    =    559.7 : 1.0\n",
      "      contains(everyday) = True           sli_ne : pos    =    519.0 : 1.0\n",
      "          contains(sick) = True              neg : pos    =    460.5 : 1.0\n",
      "           contains(due) = True           sli_ne : pos    =    455.2 : 1.0\n",
      "        contains(tediou) = True              neg : sli_po =    428.6 : 1.0\n",
      "         contains(heavi) = True           sli_ne : pos    =    408.8 : 1.0\n",
      "         contains(littl) = True           sli_ne : pos    =    395.1 : 1.0\n",
      "         contains(great) = True              pos : neg    =    387.4 : 1.0\n",
      "          contains(hate) = True              neg : sli_po =    369.8 : 1.0\n",
      "         contains(typic) = True           sli_ne : pos    =    333.7 : 1.0\n",
      "          contains(slow) = True           sli_ne : pos    =    330.1 : 1.0\n",
      "          contains(poor) = True              neg : pos    =    272.9 : 1.0\n",
      "          contains(good) = True              pos : neg    =    246.8 : 1.0\n",
      "         contains(angri) = True              neg : sli_po =    232.7 : 1.0\n",
      "          contains(best) = True              pos : neutra =    225.3 : 1.0\n",
      "          contains(lift) = True           sli_ne : pos    =    199.1 : 1.0\n",
      "        contains(random) = True              neg : pos    =    194.6 : 1.0\n",
      "       contains(destroy) = True           sli_ne : pos    =    193.4 : 1.0\n",
      "          contains(late) = True           sli_ne : pos    =    182.5 : 1.0\n",
      "         contains(badli) = True              neg : sli_po =    175.5 : 1.0\n",
      "         contains(dirti) = True              neg : sli_po =    175.5 : 1.0\n",
      "         contains(worst) = True              neg : neutra =    174.6 : 1.0\n",
      "          contains(fail) = True              neg : neutra =    174.5 : 1.0\n",
      "         contains(spent) = True           sli_ne : pos    =    171.3 : 1.0\n",
      "       contains(tiresom) = True              neg : sli_po =    167.4 : 1.0\n",
      "        contains(nearli) = True              neg : pos    =    165.2 : 1.0\n",
      "        contains(unfair) = True              neg : sli_po =    164.6 : 1.0\n",
      "         contains(wrong) = True              neg : sli_po =    161.2 : 1.0\n",
      "         contains(faint) = True              neg : pos    =    157.9 : 1.0\n",
      "         contains(happi) = True              pos : neutra =    157.8 : 1.0\n",
      "          contains(acut) = True              pos : sli_po =    156.8 : 1.0\n",
      "          contains(fair) = True              pos : neutra =    156.4 : 1.0\n",
      "          contains(less) = True           sli_ne : pos    =    155.2 : 1.0\n",
      "        contains(afraid) = True              neg : sli_po =    151.0 : 1.0\n",
      "         contains(crazi) = True              neg : sli_po =    150.3 : 1.0\n",
      "          contains(amaz) = True              pos : neutra =    148.8 : 1.0\n",
      "        contains(imposs) = True              neg : sli_po =    147.8 : 1.0\n",
      "          contains(wide) = True           sli_ne : pos    =    146.7 : 1.0\n",
      "          contains(cold) = True              neg : sli_po =    145.6 : 1.0\n",
      "        contains(center) = True           sli_ne : pos    =    126.1 : 1.0\n",
      "           contains(sad) = True              neg : sli_po =    125.8 : 1.0\n",
      "      contains(scenario) = True           sli_po : pos    =    124.7 : 1.0\n",
      "         contains(miser) = True              neg : neutra =    119.0 : 1.0\n",
      "        contains(awesom) = True              pos : neutra =    118.1 : 1.0\n",
      "       contains(perfect) = True              pos : sli_ne =    117.5 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save  the model\n",
    "with open('naive_bayes_model','w') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "#with open('naive_bayes_model') as f:\n",
    "#    classifier=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
