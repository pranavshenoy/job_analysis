{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from nltk.stem import  PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import enchant\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialising dictionary, tokenizer, stemmer\n",
    "dictionary = enchant.Dict(\"en_US\")\n",
    "tokenizer=RegexpTokenizer('[a-zA-Z]+')\n",
    "ps=PorterStemmer()\n",
    "all_stopwords=stopwords.words('english')+['ism','amazon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset():  \n",
    "    dataset=[]\n",
    "    for root, dirs, files in os.walk('../Dataset'):\n",
    "        for directory in dirs:\n",
    "            for root_f, dirs_f, files_f in os.walk(os.path.join(root,directory)):\n",
    "                for each_file in files_f:\n",
    "                    with open(os.path.join(root,directory)+'/'+each_file) as f:\n",
    "                        data_temp=json.load(f)\n",
    "                    dataset=preprocess(data_temp[:5])  \n",
    "                    #with open(os.path.join(root,directory)+'/'+each_file,'w') as f:\n",
    "                    #    json.dump(dataset,f)\n",
    "                    print each_file+' completed'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    dataset=[]\n",
    "    for sentence in data:\n",
    "        print 'sentence : '+sentence\n",
    "        temp=tokenizer.tokenize(sentence)\n",
    "        print 'tokenizer : '+str(temp)\n",
    "        remove_stopword=[word for word in temp if word not in all_stopwords]    # removing stopwords\n",
    "        print 'stopwords : '+ str(remove_stopword)\n",
    "        only_english=[ps.stem(word) for word in remove_stopword if dictionary.check(word)== True]  # remove non-english words\n",
    "        print 'removed all non-english words : '+str(only_english)\n",
    "        print ' '\n",
    "        if(len(only_english)>1):                  #appends only if length of list >1\n",
    "            dataset.append(' '.join(only_english))\n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence : help gain train intern women\n",
      "tokenizer : [u'help', u'gain', u'train', u'intern', u'women']\n",
      "stopwords : [u'help', u'gain', u'train', u'intern', u'women']\n",
      "removed all non-english words : [u'help', u'gain', u'train', u'intern', u'women']\n",
      " \n",
      "sentence : use train\n",
      "tokenizer : [u'use', u'train']\n",
      "stopwords : [u'use', u'train']\n",
      "removed all non-english words : [u'use', u'train']\n",
      " \n",
      "sentence : enjoy work\n",
      "tokenizer : [u'enjoy', u'work']\n",
      "stopwords : [u'enjoy', u'work']\n",
      "removed all non-english words : [u'enjoy', u'work']\n",
      " \n",
      "sli_pos completed\n",
      "neutral completed\n",
      "sentence : place work\n",
      "tokenizer : [u'place', u'work']\n",
      "stopwords : [u'place', u'work']\n",
      "removed all non-english words : [u'place', u'work']\n",
      " \n",
      "sentence : proud organ\n",
      "tokenizer : [u'proud', u'organ']\n",
      "stopwords : [u'proud', u'organ']\n",
      "removed all non-english words : [u'proud', u'organ']\n",
      " \n",
      "sentence : good client\n",
      "tokenizer : [u'good', u'client']\n",
      "stopwords : [u'good', u'client']\n",
      "removed all non-english words : [u'good', u'client']\n",
      " \n",
      "sentence : one best band work\n",
      "tokenizer : [u'one', u'best', u'band', u'work']\n",
      "stopwords : [u'one', u'best', u'band', u'work']\n",
      "removed all non-english words : [u'one', u'best', u'band', u'work']\n",
      " \n",
      "pos completed\n",
      "sentence : limitless sick\n",
      "tokenizer : [u'limitless', u'sick']\n",
      "stopwords : [u'limitless', u'sick']\n",
      "removed all non-english words : [u'limitless', u'sick']\n",
      " \n",
      "sentence : bad work\n",
      "tokenizer : [u'bad', u'work']\n",
      "stopwords : [u'bad', u'work']\n",
      "removed all non-english words : [u'bad', u'work']\n",
      " \n",
      "sentence : travel flight\n",
      "tokenizer : [u'travel', u'flight']\n",
      "stopwords : [u'travel', u'flight']\n",
      "removed all non-english words : [u'travel', u'flight']\n",
      " \n",
      "sentence : never felt pain\n",
      "tokenizer : [u'never', u'felt', u'pain']\n",
      "stopwords : [u'never', u'felt', u'pain']\n",
      "removed all non-english words : [u'never', u'felt', u'pain']\n",
      " \n",
      "sentence : accord percept hardest part job night shift till girl difficult\n",
      "tokenizer : [u'accord', u'percept', u'hardest', u'part', u'job', u'night', u'shift', u'till', u'girl', u'difficult']\n",
      "stopwords : [u'accord', u'percept', u'hardest', u'part', u'job', u'night', u'shift', u'till', u'girl', u'difficult']\n",
      "removed all non-english words : [u'accord', u'percept', u'hardest', u'part', u'job', u'night', u'shift', u'till', u'girl', u'difficult']\n",
      " \n",
      "neg completed\n",
      "sentence : year give sudden like\n",
      "tokenizer : [u'year', u'give', u'sudden', u'like']\n",
      "stopwords : [u'year', u'give', u'sudden', u'like']\n",
      "removed all non-english words : [u'year', u'give', u'sudden', u'like']\n",
      " \n",
      "sentence : feat hard\n",
      "tokenizer : [u'feat', u'hard']\n",
      "stopwords : [u'feat', u'hard']\n",
      "removed all non-english words : [u'feat', u'hard']\n",
      " \n",
      "sentence : day work like day home\n",
      "tokenizer : [u'day', u'work', u'like', u'day', u'home']\n",
      "stopwords : [u'day', u'work', u'like', u'day', u'home']\n",
      "removed all non-english words : [u'day', u'work', u'like', u'day', u'home']\n",
      " \n",
      "sentence : expect brand\n",
      "tokenizer : [u'expect', u'brand']\n",
      "stopwords : [u'expect', u'brand']\n",
      "removed all non-english words : [u'expect', u'brand']\n",
      " \n",
      "sentence : less increment\n",
      "tokenizer : [u'less', u'increment']\n",
      "stopwords : [u'less', u'increment']\n",
      "removed all non-english words : [u'less', u'increment']\n",
      " \n",
      "sli_neg completed\n",
      "sentence : work global client\n",
      "tokenizer : [u'work', u'global', u'client']\n",
      "stopwords : [u'work', u'global', u'client']\n",
      "removed all non-english words : [u'work', u'global', u'client']\n",
      " \n",
      "sentence : lot scope learn new like cloud\n",
      "tokenizer : [u'lot', u'scope', u'learn', u'new', u'like', u'cloud']\n",
      "stopwords : [u'lot', u'scope', u'learn', u'new', u'like', u'cloud']\n",
      "removed all non-english words : [u'lot', u'scope', u'learn', u'new', u'like', u'cloud']\n",
      " \n",
      "sentence : learn thing first multi nation find differ work\n",
      "tokenizer : [u'learn', u'thing', u'first', u'multi', u'nation', u'find', u'differ', u'work']\n",
      "stopwords : [u'learn', u'thing', u'first', u'multi', u'nation', u'find', u'differ', u'work']\n",
      "removed all non-english words : [u'learn', u'thing', u'first', u'multi', u'nation', u'find', u'differ', u'work']\n",
      " \n",
      "sentence : good place learn new thing\n",
      "tokenizer : [u'good', u'place', u'learn', u'new', u'thing']\n",
      "stopwords : [u'good', u'place', u'learn', u'new', u'thing']\n",
      "removed all non-english words : [u'good', u'place', u'learn', u'new', u'thing']\n",
      " \n",
      "sentence : good place learn differ tool\n",
      "tokenizer : [u'good', u'place', u'learn', u'differ', u'tool']\n",
      "stopwords : [u'good', u'place', u'learn', u'differ', u'tool']\n",
      "removed all non-english words : [u'good', u'place', u'learn', u'differ', u'tool']\n",
      " \n",
      "sli_pos completed\n",
      "sentence : term career\n",
      "tokenizer : [u'term', u'career']\n",
      "stopwords : [u'term', u'career']\n",
      "removed all non-english words : [u'term', u'career']\n",
      " \n",
      "sentence : work project learn\n",
      "tokenizer : [u'work', u'project', u'learn']\n",
      "stopwords : [u'work', u'project', u'learn']\n",
      "removed all non-english words : [u'work', u'project', u'learn']\n",
      " \n",
      "sentence : lot learn\n",
      "tokenizer : [u'lot', u'learn']\n",
      "stopwords : [u'lot', u'learn']\n",
      "removed all non-english words : [u'lot', u'learn']\n",
      " \n",
      "sentence : work world place\n",
      "tokenizer : [u'work', u'world', u'place']\n",
      "stopwords : [u'work', u'world', u'place']\n",
      "removed all non-english words : [u'work', u'world', u'place']\n",
      " \n",
      "neutral completed\n",
      "sentence : great place learn\n",
      "tokenizer : [u'great', u'place', u'learn']\n",
      "stopwords : [u'great', u'place', u'learn']\n",
      "removed all non-english words : [u'great', u'place', u'learn']\n",
      " \n",
      "sentence : great unit learn lot alway fun\n",
      "tokenizer : [u'great', u'unit', u'learn', u'lot', u'alway', u'fun']\n",
      "stopwords : [u'great', u'unit', u'learn', u'lot', u'alway', u'fun']\n",
      "removed all non-english words : [u'great', u'unit', u'learn', u'lot', u'alway', u'fun']\n",
      " \n",
      "sentence : get good work learn\n",
      "tokenizer : [u'get', u'good', u'work', u'learn']\n",
      "stopwords : [u'get', u'good', u'work', u'learn']\n",
      "removed all non-english words : [u'get', u'good', u'work', u'learn']\n",
      " \n",
      "sentence : give great work\n",
      "tokenizer : [u'give', u'great', u'work']\n",
      "stopwords : [u'give', u'great', u'work']\n",
      "removed all non-english words : [u'give', u'great', u'work']\n",
      " \n",
      "sentence : good environ great learn learn thing job\n",
      "tokenizer : [u'good', u'environ', u'great', u'learn', u'learn', u'thing', u'job']\n",
      "stopwords : [u'good', u'environ', u'great', u'learn', u'learn', u'thing', u'job']\n",
      "removed all non-english words : [u'good', u'environ', u'great', u'learn', u'learn', u'thing', u'job']\n",
      " \n",
      "pos completed\n",
      "sentence : custom deal skill bit difficult\n",
      "tokenizer : [u'custom', u'deal', u'skill', u'bit', u'difficult']\n",
      "stopwords : [u'custom', u'deal', u'skill', u'bit', u'difficult']\n",
      "removed all non-english words : [u'custom', u'deal', u'skill', u'bit', u'difficult']\n",
      " \n",
      "sentence : best growth part\n",
      "tokenizer : [u'best', u'growth', u'part']\n",
      "stopwords : [u'best', u'growth', u'part']\n",
      "removed all non-english words : [u'best', u'growth', u'part']\n",
      " \n",
      "sentence : learn cope bad\n",
      "tokenizer : [u'learn', u'cope', u'bad']\n",
      "stopwords : [u'learn', u'cope', u'bad']\n",
      "removed all non-english words : [u'learn', u'cope', u'bad']\n",
      " \n",
      "sentence : learn take care custom bad\n",
      "tokenizer : [u'learn', u'take', u'care', u'custom', u'bad']\n",
      "stopwords : [u'learn', u'take', u'care', u'custom', u'bad']\n",
      "removed all non-english words : [u'learn', u'take', u'care', u'custom', u'bad']\n",
      " \n",
      "sentence : skill find\n",
      "tokenizer : [u'skill', u'find']\n",
      "stopwords : [u'skill', u'find']\n",
      "removed all non-english words : [u'skill', u'find']\n",
      " \n",
      "neg completed\n",
      "sentence : career look\n",
      "tokenizer : [u'career', u'look']\n",
      "stopwords : [u'career', u'look']\n",
      "removed all non-english words : [u'career', u'look']\n",
      " \n",
      "sentence : slow growth\n",
      "tokenizer : [u'slow', u'growth']\n",
      "stopwords : [u'slow', u'growth']\n",
      "removed all non-english words : [u'slow', u'growth']\n",
      " \n",
      "sentence : less growth\n",
      "tokenizer : [u'less', u'growth']\n",
      "stopwords : [u'less', u'growth']\n",
      "removed all non-english words : [u'less', u'growth']\n",
      " \n",
      "sentence : put lower level work fail due lack skill\n",
      "tokenizer : [u'put', u'lower', u'level', u'work', u'fail', u'due', u'lack', u'skill']\n",
      "stopwords : [u'put', u'lower', u'level', u'work', u'fail', u'due', u'lack', u'skill']\n",
      "removed all non-english words : [u'put', u'lower', u'level', u'work', u'fail', u'due', u'lack', u'skill']\n",
      " \n",
      "sentence : learn environ look like\n",
      "tokenizer : [u'learn', u'environ', u'look', u'like']\n",
      "stopwords : [u'learn', u'environ', u'look', u'like']\n",
      "removed all non-english words : [u'learn', u'environ', u'look', u'like']\n",
      " \n",
      "sli_neg completed\n",
      "sentence : work life\n",
      "tokenizer : [u'work', u'life']\n",
      "stopwords : [u'work', u'life']\n",
      "removed all non-english words : [u'work', u'life']\n",
      " \n",
      "sentence : person life work home option avail\n",
      "tokenizer : [u'person', u'life', u'work', u'home', u'option', u'avail']\n",
      "stopwords : [u'person', u'life', u'work', u'home', u'option', u'avail']\n",
      "removed all non-english words : [u'person', u'life', u'work', u'home', u'option', u'avail']\n",
      " \n",
      "sentence : fun time team\n",
      "tokenizer : [u'fun', u'time', u'team']\n",
      "stopwords : [u'fun', u'time', u'team']\n",
      "removed all non-english words : [u'fun', u'time', u'team']\n",
      " \n",
      "sentence : enjoy part job finish task given time frame\n",
      "tokenizer : [u'enjoy', u'part', u'job', u'finish', u'task', u'given', u'time', u'frame']\n",
      "stopwords : [u'enjoy', u'part', u'job', u'finish', u'task', u'given', u'time', u'frame']\n",
      "removed all non-english words : [u'enjoy', u'part', u'job', u'finish', u'task', u'given', u'time', u'frame']\n",
      " \n",
      "sentence : work place product learn skill work time\n",
      "tokenizer : [u'work', u'place', u'product', u'learn', u'skill', u'work', u'time']\n",
      "stopwords : [u'work', u'place', u'product', u'learn', u'skill', u'work', u'time']\n",
      "removed all non-english words : [u'work', u'place', u'product', u'learn', u'skill', u'work', u'time']\n",
      " \n",
      "sli_pos completed\n",
      "sentence : entertain son work life limit expo product\n",
      "tokenizer : [u'entertain', u'son', u'work', u'life', u'limit', u'expo', u'product']\n",
      "stopwords : [u'entertain', u'son', u'work', u'life', u'limit', u'expo', u'product']\n",
      "removed all non-english words : [u'entertain', u'son', u'work', u'life', u'limit', u'expo', u'product']\n",
      " \n",
      "sentence : take care work life\n",
      "tokenizer : [u'take', u'care', u'work', u'life']\n",
      "stopwords : [u'take', u'care', u'work', u'life']\n",
      "removed all non-english words : [u'take', u'care', u'work', u'life']\n",
      " \n",
      "sentence : minim perform\n",
      "tokenizer : [u'minim', u'perform']\n",
      "stopwords : [u'minim', u'perform']\n",
      "removed all non-english words : [u'minim', u'perform']\n",
      " \n",
      "sentence : time restrict put\n",
      "tokenizer : [u'time', u'restrict', u'put']\n",
      "stopwords : [u'time', u'restrict', u'put']\n",
      "removed all non-english words : [u'time', u'restrict', u'put']\n",
      " \n",
      "neutral completed\n",
      "sentence : good work life mark per\n",
      "tokenizer : [u'good', u'work', u'life', u'mark', u'per']\n",
      "stopwords : [u'good', u'work', u'life', u'mark', u'per']\n",
      "removed all non-english words : [u'good', u'work', u'life', u'mark', u'per']\n",
      " \n",
      "sentence : good work hour work tear\n",
      "tokenizer : [u'good', u'work', u'hour', u'work', u'tear']\n",
      "stopwords : [u'good', u'work', u'hour', u'work', u'tear']\n",
      "removed all non-english words : [u'good', u'work', u'hour', u'work', u'tear']\n",
      " \n",
      "sentence : nice work life\n",
      "tokenizer : [u'nice', u'work', u'life']\n",
      "stopwords : [u'nice', u'work', u'life']\n",
      "removed all non-english words : [u'nice', u'work', u'life']\n",
      " \n",
      "sentence : first class great work life\n",
      "tokenizer : [u'first', u'class', u'great', u'work', u'life']\n",
      "stopwords : [u'first', u'class', u'great', u'work', u'life']\n",
      "removed all non-english words : [u'first', u'class', u'great', u'work', u'life']\n",
      " \n",
      "sentence : excel work home\n",
      "tokenizer : [u'excel', u'work', u'home']\n",
      "stopwords : [u'excel', u'work', u'home']\n",
      "removed all non-english words : [u'excel', u'work', u'home']\n",
      " \n",
      "pos completed\n",
      "sentence : peak though tide work home\n",
      "tokenizer : [u'peak', u'though', u'tide', u'work', u'home']\n",
      "stopwords : [u'peak', u'though', u'tide', u'work', u'home']\n",
      "removed all non-english words : [u'peak', u'though', u'tide', u'work', u'home']\n",
      " \n",
      "sentence : bad term work life\n",
      "tokenizer : [u'bad', u'term', u'work', u'life']\n",
      "stopwords : [u'bad', u'term', u'work', u'life']\n",
      "removed all non-english words : [u'bad', u'term', u'work', u'life']\n",
      " \n",
      "sentence : work life difficult maintain job accord us tide\n",
      "tokenizer : [u'work', u'life', u'difficult', u'maintain', u'job', u'accord', u'us', u'tide']\n",
      "stopwords : [u'work', u'life', u'difficult', u'maintain', u'job', u'accord', u'us', u'tide']\n",
      "removed all non-english words : [u'work', u'life', u'difficult', u'maintain', u'job', u'accord', u'us', u'tide']\n",
      " \n",
      "sentence : difficult maintain work life\n",
      "tokenizer : [u'difficult', u'maintain', u'work', u'life']\n",
      "stopwords : [u'difficult', u'maintain', u'work', u'life']\n",
      "removed all non-english words : [u'difficult', u'maintain', u'work', u'life']\n",
      " \n",
      "sentence : start feel bore personnel life\n",
      "tokenizer : [u'start', u'feel', u'bore', u'personnel', u'life']\n",
      "stopwords : [u'start', u'feel', u'bore', u'personnel', u'life']\n",
      "removed all non-english words : [u'start', u'feel', u'bore', u'personnel', u'life']\n",
      " \n",
      "neg completed\n",
      "sentence : day day learn process difficult time site\n",
      "tokenizer : [u'day', u'day', u'learn', u'process', u'difficult', u'time', u'site']\n",
      "stopwords : [u'day', u'day', u'learn', u'process', u'difficult', u'time', u'site']\n",
      "removed all non-english words : [u'day', u'day', u'learn', u'process', u'difficult', u'time', u'site']\n",
      " \n",
      "sentence : come work life sick day\n",
      "tokenizer : [u'come', u'work', u'life', u'sick', u'day']\n",
      "stopwords : [u'come', u'work', u'life', u'sick', u'day']\n",
      "removed all non-english words : [u'come', u'work', u'life', u'sick', u'day']\n",
      " \n",
      "sentence : spent time listen\n",
      "tokenizer : [u'spent', u'time', u'listen']\n",
      "stopwords : [u'spent', u'time', u'listen']\n",
      "removed all non-english words : [u'spent', u'time', u'listen']\n",
      " \n",
      "sentence : less grow differ time\n",
      "tokenizer : [u'less', u'grow', u'differ', u'time']\n",
      "stopwords : [u'less', u'grow', u'differ', u'time']\n",
      "removed all non-english words : [u'less', u'grow', u'differ', u'time']\n",
      " \n",
      "sentence : small thing expel could save critic time month close\n",
      "tokenizer : [u'small', u'thing', u'expel', u'could', u'save', u'critic', u'time', u'month', u'close']\n",
      "stopwords : [u'small', u'thing', u'expel', u'could', u'save', u'critic', u'time', u'month', u'close']\n",
      "removed all non-english words : [u'small', u'thing', u'expel', u'could', u'save', u'critic', u'time', u'month', u'close']\n",
      " \n",
      "sli_neg completed\n",
      "sentence : work avail\n",
      "tokenizer : [u'work', u'avail']\n",
      "stopwords : [u'work', u'avail']\n",
      "removed all non-english words : [u'work', u'avail']\n",
      " \n",
      "sentence : good respect well good like work home etc\n",
      "tokenizer : [u'good', u'respect', u'well', u'good', u'like', u'work', u'home', u'etc']\n",
      "stopwords : [u'good', u'respect', u'well', u'good', u'like', u'work', u'home', u'etc']\n",
      "removed all non-english words : [u'good', u'respect', u'well', u'good', u'like', u'work', u'home', u'etc']\n",
      " \n",
      "sentence : look role test test test role thank much\n",
      "tokenizer : [u'look', u'role', u'test', u'test', u'test', u'role', u'thank', u'much']\n",
      "stopwords : [u'look', u'role', u'test', u'test', u'test', u'role', u'thank', u'much']\n",
      "removed all non-english words : [u'look', u'role', u'test', u'test', u'test', u'role', u'thank', u'much']\n",
      " \n",
      "sentence : good complex good good co\n",
      "tokenizer : [u'good', u'complex', u'good', u'good', u'co']\n",
      "stopwords : [u'good', u'complex', u'good', u'good', u'co']\n",
      "removed all non-english words : [u'good', u'complex', u'good', u'good', u'co']\n",
      " \n",
      "sentence : lap top like short game\n",
      "tokenizer : [u'lap', u'top', u'like', u'short', u'game']\n",
      "stopwords : [u'lap', u'top', u'like', u'short', u'game']\n",
      "removed all non-english words : [u'lap', u'top', u'like', u'short', u'game']\n",
      " \n",
      "sli_pos completed\n",
      "sentence : work project learn\n",
      "tokenizer : [u'work', u'project', u'learn']\n",
      "stopwords : [u'work', u'project', u'learn']\n",
      "removed all non-english words : [u'work', u'project', u'learn']\n",
      " \n",
      "sentence : impress worst cab\n",
      "tokenizer : [u'impress', u'worst', u'cab']\n",
      "stopwords : [u'impress', u'worst', u'cab']\n",
      "removed all non-english words : [u'impress', u'worst', u'cab']\n",
      " \n",
      "sentence : good take care like case person sick\n",
      "tokenizer : [u'good', u'take', u'care', u'like', u'case', u'person', u'sick']\n",
      "stopwords : [u'good', u'take', u'care', u'like', u'case', u'person', u'sick']\n",
      "removed all non-english words : [u'good', u'take', u'care', u'like', u'case', u'person', u'sick']\n",
      " \n",
      "sentence : milk could two way cab\n",
      "tokenizer : [u'milk', u'could', u'two', u'way', u'cab']\n",
      "stopwords : [u'milk', u'could', u'two', u'way', u'cab']\n",
      "removed all non-english words : [u'milk', u'could', u'two', u'way', u'cab']\n",
      " \n",
      "neutral completed\n",
      "sentence : good transport\n",
      "tokenizer : [u'good', u'transport']\n",
      "stopwords : [u'good', u'transport']\n",
      "removed all non-english words : [u'good', u'transport']\n",
      " \n",
      "sentence : co worker law also avail good time work\n",
      "tokenizer : [u'co', u'worker', u'law', u'also', u'avail', u'good', u'time', u'work']\n",
      "stopwords : [u'co', u'worker', u'law', u'also', u'avail', u'good', u'time', u'work']\n",
      "removed all non-english words : [u'co', u'worker', u'law', u'also', u'avail', u'good', u'time', u'work']\n",
      " \n",
      "sentence : cafeteria good\n",
      "tokenizer : [u'cafeteria', u'good']\n",
      "stopwords : [u'cafeteria', u'good']\n",
      "removed all non-english words : [u'cafeteria', u'good']\n",
      " \n",
      "pos completed\n",
      "sentence : peak though tide work home\n",
      "tokenizer : [u'peak', u'though', u'tide', u'work', u'home']\n",
      "stopwords : [u'peak', u'though', u'tide', u'work', u'home']\n",
      "removed all non-english words : [u'peak', u'though', u'tide', u'work', u'home']\n",
      " \n",
      "sentence : peak though tide work home\n",
      "tokenizer : [u'peak', u'though', u'tide', u'work', u'home']\n",
      "stopwords : [u'peak', u'though', u'tide', u'work', u'home']\n",
      "removed all non-english words : [u'peak', u'though', u'tide', u'work', u'home']\n",
      " \n",
      "sentence : work home one sick well\n",
      "tokenizer : [u'work', u'home', u'one', u'sick', u'well']\n",
      "stopwords : [u'work', u'home', u'one', u'sick', u'well']\n",
      "removed all non-english words : [u'work', u'home', u'one', u'sick', u'well']\n",
      " \n",
      "sentence : room move recommend phone make break bore\n",
      "tokenizer : [u'room', u'move', u'recommend', u'phone', u'make', u'break', u'bore']\n",
      "stopwords : [u'room', u'move', u'recommend', u'phone', u'make', u'break', u'bore']\n",
      "removed all non-english words : [u'room', u'move', u'recommend', u'phone', u'make', u'break', u'bore']\n",
      " \n",
      "neg completed\n",
      "sentence : basic job less fit work good project alway work worst\n",
      "tokenizer : [u'basic', u'job', u'less', u'fit', u'work', u'good', u'project', u'alway', u'work', u'worst']\n",
      "stopwords : [u'basic', u'job', u'less', u'fit', u'work', u'good', u'project', u'alway', u'work', u'worst']\n",
      "removed all non-english words : [u'basic', u'job', u'less', u'fit', u'work', u'good', u'project', u'alway', u'work', u'worst']\n",
      " \n",
      "sentence : basic job less fit work good project alway work worst\n",
      "tokenizer : [u'basic', u'job', u'less', u'fit', u'work', u'good', u'project', u'alway', u'work', u'worst']\n",
      "stopwords : [u'basic', u'job', u'less', u'fit', u'work', u'good', u'project', u'alway', u'work', u'worst']\n",
      "removed all non-english words : [u'basic', u'job', u'less', u'fit', u'work', u'good', u'project', u'alway', u'work', u'worst']\n",
      " \n",
      "sentence : write complex\n",
      "tokenizer : [u'write', u'complex']\n",
      "stopwords : [u'write', u'complex']\n",
      "removed all non-english words : [u'write', u'complex']\n",
      " \n",
      "sentence : drop help hard part irregular break\n",
      "tokenizer : [u'drop', u'help', u'hard', u'part', u'irregular', u'break']\n",
      "stopwords : [u'drop', u'help', u'hard', u'part', u'irregular', u'break']\n",
      "removed all non-english words : [u'drop', u'help', u'hard', u'part', u'irregular', u'break']\n",
      " \n",
      "sentence : drop help hard part irregular break\n",
      "tokenizer : [u'drop', u'help', u'hard', u'part', u'irregular', u'break']\n",
      "stopwords : [u'drop', u'help', u'hard', u'part', u'irregular', u'break']\n",
      "removed all non-english words : [u'drop', u'help', u'hard', u'part', u'irregular', u'break']\n",
      " \n",
      "sli_neg completed\n",
      "sentence : enjoy part job among team member\n",
      "tokenizer : [u'enjoy', u'part', u'job', u'among', u'team', u'member']\n",
      "stopwords : [u'enjoy', u'part', u'job', u'among', u'team', u'member']\n",
      "removed all non-english words : [u'enjoy', u'part', u'job', u'among', u'team', u'member']\n",
      " \n",
      "sentence : learn matrix mix profess\n",
      "tokenizer : [u'learn', u'matrix', u'mix', u'profess']\n",
      "stopwords : [u'learn', u'matrix', u'mix', u'profess']\n",
      "removed all non-english words : [u'learn', u'matrix', u'mix', u'profess']\n",
      " \n",
      "sentence : project demand client career option diver reason sponsor\n",
      "tokenizer : [u'project', u'demand', u'client', u'career', u'option', u'diver', u'reason', u'sponsor']\n",
      "stopwords : [u'project', u'demand', u'client', u'career', u'option', u'diver', u'reason', u'sponsor']\n",
      "removed all non-english words : [u'project', u'demand', u'client', u'career', u'option', u'diver', u'reason', u'sponsor']\n",
      " \n",
      "sentence : fun time team\n",
      "tokenizer : [u'fun', u'time', u'team']\n",
      "stopwords : [u'fun', u'time', u'team']\n",
      "removed all non-english words : [u'fun', u'time', u'team']\n",
      " \n",
      "sli_pos completed\n",
      "sentence : urgent job need demand team\n",
      "tokenizer : [u'urgent', u'job', u'need', u'demand', u'team']\n",
      "stopwords : [u'urgent', u'job', u'need', u'demand', u'team']\n",
      "removed all non-english words : [u'urgent', u'job', u'need', u'demand', u'team']\n",
      " \n",
      "neutral completed\n",
      "sentence : great team meet\n",
      "tokenizer : [u'great', u'team', u'meet']\n",
      "stopwords : [u'great', u'team', u'meet']\n",
      "removed all non-english words : [u'great', u'team', u'meet']\n",
      " \n",
      "sentence : good place folk design\n",
      "tokenizer : [u'good', u'place', u'folk', u'design']\n",
      "stopwords : [u'good', u'place', u'folk', u'design']\n",
      "removed all non-english words : [u'good', u'place', u'folk', u'design']\n",
      " \n",
      "sentence : good team outing\n",
      "tokenizer : [u'good', u'team', u'outing']\n",
      "stopwords : [u'good', u'team', u'outing']\n",
      "removed all non-english words : [u'good', u'team', u'outing']\n",
      " \n",
      "pos completed\n",
      "sentence : custom deal skill bit difficult\n",
      "tokenizer : [u'custom', u'deal', u'skill', u'bit', u'difficult']\n",
      "stopwords : [u'custom', u'deal', u'skill', u'bit', u'difficult']\n",
      "removed all non-english words : [u'custom', u'deal', u'skill', u'bit', u'difficult']\n",
      " \n",
      "sentence : worst part process\n",
      "tokenizer : [u'worst', u'part', u'process']\n",
      "stopwords : [u'worst', u'part', u'process']\n",
      "removed all non-english words : [u'worst', u'part', u'process']\n",
      " \n",
      "sentence : lack amp useless work\n",
      "tokenizer : [u'lack', u'amp', u'useless', u'work']\n",
      "stopwords : [u'lack', u'amp', u'useless', u'work']\n",
      "removed all non-english words : [u'lack', u'amp', u'useless', u'work']\n",
      " \n",
      "neg completed\n",
      "sentence : grow lower side need support work hour stretch past midnight\n",
      "tokenizer : [u'grow', u'lower', u'side', u'need', u'support', u'work', u'hour', u'stretch', u'past', u'midnight']\n",
      "stopwords : [u'grow', u'lower', u'side', u'need', u'support', u'work', u'hour', u'stretch', u'past', u'midnight']\n",
      "removed all non-english words : [u'grow', u'lower', u'side', u'need', u'support', u'work', u'hour', u'stretch', u'past', u'midnight']\n",
      " \n",
      "sentence : weak process total control\n",
      "tokenizer : [u'weak', u'process', u'total', u'control']\n",
      "stopwords : [u'weak', u'process', u'total', u'control']\n",
      "removed all non-english words : [u'weak', u'process', u'total', u'control']\n",
      " \n",
      "sentence : day day learn process difficult time site\n",
      "tokenizer : [u'day', u'day', u'learn', u'process', u'difficult', u'time', u'site']\n",
      "stopwords : [u'day', u'day', u'learn', u'process', u'difficult', u'time', u'site']\n",
      "removed all non-english words : [u'day', u'day', u'learn', u'process', u'difficult', u'time', u'site']\n",
      " \n",
      "sli_neg completed\n",
      "sentence : user environ fun\n",
      "tokenizer : [u'user', u'environ', u'fun']\n",
      "stopwords : [u'user', u'environ', u'fun']\n",
      "removed all non-english words : [u'user', u'environ', u'fun']\n",
      " \n",
      "sentence : work great field\n",
      "tokenizer : [u'work', u'great', u'field']\n",
      "stopwords : [u'work', u'great', u'field']\n",
      "removed all non-english words : [u'work', u'great', u'field']\n",
      " \n",
      "sentence : learn thing first multi nation find differ work\n",
      "tokenizer : [u'learn', u'thing', u'first', u'multi', u'nation', u'find', u'differ', u'work']\n",
      "stopwords : [u'learn', u'thing', u'first', u'multi', u'nation', u'find', u'differ', u'work']\n",
      "removed all non-english words : [u'learn', u'thing', u'first', u'multi', u'nation', u'find', u'differ', u'work']\n",
      " \n",
      "sentence : differ work alway good\n",
      "tokenizer : [u'differ', u'work', u'alway', u'good']\n",
      "stopwords : [u'differ', u'work', u'alway', u'good']\n",
      "removed all non-english words : [u'differ', u'work', u'alway', u'good']\n",
      " \n",
      "sentence : fast pace environ\n",
      "tokenizer : [u'fast', u'pace', u'environ']\n",
      "stopwords : [u'fast', u'pace', u'environ']\n",
      "removed all non-english words : [u'fast', u'pace', u'environ']\n",
      " \n",
      "sli_pos completed\n",
      "sentence : overcrowd team due much proof one perform\n",
      "tokenizer : [u'overcrowd', u'team', u'due', u'much', u'proof', u'one', u'perform']\n",
      "stopwords : [u'overcrowd', u'team', u'due', u'much', u'proof', u'one', u'perform']\n",
      "removed all non-english words : [u'overcrowd', u'team', u'due', u'much', u'proof', u'one', u'perform']\n",
      " \n",
      "sentence : work inter pro vagrant\n",
      "tokenizer : [u'work', u'inter', u'pro', u'vagrant']\n",
      "stopwords : [u'work', u'inter', u'pro', u'vagrant']\n",
      "removed all non-english words : [u'work', u'inter', u'pro', u'vagrant']\n",
      " \n",
      "sentence : ad stagnant\n",
      "tokenizer : [u'ad', u'stagnant']\n",
      "stopwords : [u'ad', u'stagnant']\n",
      "removed all non-english words : [u'ad', u'stagnant']\n",
      " \n",
      "sentence : profess environ\n",
      "tokenizer : [u'profess', u'environ']\n",
      "stopwords : [u'profess', u'environ']\n",
      "removed all non-english words : [u'profess', u'environ']\n",
      " \n",
      "neutral completed\n",
      "sentence : good work hour work tear\n",
      "tokenizer : [u'good', u'work', u'hour', u'work', u'tear']\n",
      "stopwords : [u'good', u'work', u'hour', u'work', u'tear']\n",
      "removed all non-english words : [u'good', u'work', u'hour', u'work', u'tear']\n",
      " \n",
      "sentence : nice work\n",
      "tokenizer : [u'nice', u'work']\n",
      "stopwords : [u'nice', u'work']\n",
      "removed all non-english words : [u'nice', u'work']\n",
      " \n",
      "sentence : great work\n",
      "tokenizer : [u'great', u'work']\n",
      "stopwords : [u'great', u'work']\n",
      "removed all non-english words : [u'great', u'work']\n",
      " \n",
      "sentence : work good\n",
      "tokenizer : [u'work', u'good']\n",
      "stopwords : [u'work', u'good']\n",
      "removed all non-english words : [u'work', u'good']\n",
      " \n",
      "pos completed\n",
      "sentence : bore work\n",
      "tokenizer : [u'bore', u'work']\n",
      "stopwords : [u'bore', u'work']\n",
      "removed all non-english words : [u'bore', u'work']\n",
      " \n",
      "sentence : environ corrupt\n",
      "tokenizer : [u'environ', u'corrupt']\n",
      "stopwords : [u'environ', u'corrupt']\n",
      "removed all non-english words : [u'environ', u'corrupt']\n",
      " \n",
      "sentence : environ corrupt\n",
      "tokenizer : [u'environ', u'corrupt']\n",
      "stopwords : [u'environ', u'corrupt']\n",
      "removed all non-english words : [u'environ', u'corrupt']\n",
      " \n",
      "sentence : job worst\n",
      "tokenizer : [u'job', u'worst']\n",
      "stopwords : [u'job', u'worst']\n",
      "removed all non-english words : [u'job', u'worst']\n",
      " \n",
      "sentence : hand concept end end fail maintain sea\n",
      "tokenizer : [u'hand', u'concept', u'end', u'end', u'fail', u'maintain', u'sea']\n",
      "stopwords : [u'hand', u'concept', u'end', u'end', u'fail', u'maintain', u'sea']\n",
      "removed all non-english words : [u'hand', u'concept', u'end', u'end', u'fail', u'maintain', u'sea']\n",
      " \n",
      "neg completed\n",
      "sentence : learn environ look like\n",
      "tokenizer : [u'learn', u'environ', u'look', u'like']\n",
      "stopwords : [u'learn', u'environ', u'look', u'like']\n",
      "removed all non-english words : [u'learn', u'environ', u'look', u'like']\n",
      " \n",
      "sentence : never long call environ\n",
      "tokenizer : [u'never', u'long', u'call', u'environ']\n",
      "stopwords : [u'never', u'long', u'call', u'environ']\n",
      "removed all non-english words : [u'never', u'long', u'call', u'environ']\n",
      " \n",
      "sentence : learn environ look like\n",
      "tokenizer : [u'learn', u'environ', u'look', u'like']\n",
      "stopwords : [u'learn', u'environ', u'look', u'like']\n",
      "removed all non-english words : [u'learn', u'environ', u'look', u'like']\n",
      " \n",
      "sentence : hard work\n",
      "tokenizer : [u'hard', u'work']\n",
      "stopwords : [u'hard', u'work']\n",
      "removed all non-english words : [u'hard', u'work']\n",
      " \n",
      "sentence : good work\n",
      "tokenizer : [u'good', u'work']\n",
      "stopwords : [u'good', u'work']\n",
      "removed all non-english words : [u'good', u'work']\n",
      " \n",
      "sli_neg completed\n",
      "sentence : better learn work option mac work talent worker increment wet work done talent\n",
      "tokenizer : [u'better', u'learn', u'work', u'option', u'mac', u'work', u'talent', u'worker', u'increment', u'wet', u'work', u'done', u'talent']\n",
      "stopwords : [u'better', u'learn', u'work', u'option', u'mac', u'work', u'talent', u'worker', u'increment', u'wet', u'work', u'done', u'talent']\n",
      "removed all non-english words : [u'better', u'learn', u'work', u'option', u'mac', u'work', u'talent', u'worker', u'increment', u'wet', u'work', u'done', u'talent']\n",
      " \n",
      "sentence : could better\n",
      "tokenizer : [u'could', u'better']\n",
      "stopwords : [u'could', u'better']\n",
      "removed all non-english words : [u'could', u'better']\n",
      " \n",
      "sentence : pay rate\n",
      "tokenizer : [u'pay', u'rate']\n",
      "stopwords : [u'pay', u'rate']\n",
      "removed all non-english words : [u'pay', u'rate']\n",
      " \n",
      "sli_pos completed\n",
      "sentence : place like year year\n",
      "tokenizer : [u'place', u'like', u'year', u'year']\n",
      "stopwords : [u'place', u'like', u'year', u'year']\n",
      "removed all non-english words : [u'place', u'like', u'year', u'year']\n",
      " \n",
      "sentence : like low\n",
      "tokenizer : [u'like', u'low']\n",
      "stopwords : [u'like', u'low']\n",
      "removed all non-english words : [u'like', u'low']\n",
      " \n",
      "sentence : par push move organ\n",
      "tokenizer : [u'par', u'push', u'move', u'organ']\n",
      "stopwords : [u'par', u'push', u'move', u'organ']\n",
      "removed all non-english words : [u'par', u'push', u'move', u'organ']\n",
      " \n",
      "sentence : pay low\n",
      "tokenizer : [u'pay', u'low']\n",
      "stopwords : [u'pay', u'low']\n",
      "removed all non-english words : [u'pay', u'low']\n",
      " \n",
      "sentence : lower side peer teach\n",
      "tokenizer : [u'lower', u'side', u'peer', u'teach']\n",
      "stopwords : [u'lower', u'side', u'peer', u'teach']\n",
      "removed all non-english words : [u'lower', u'side', u'peer', u'teach']\n",
      " \n",
      "neutral completed\n",
      "sentence : good work life mark per\n",
      "tokenizer : [u'good', u'work', u'life', u'mark', u'per']\n",
      "stopwords : [u'good', u'work', u'life', u'mark', u'per']\n",
      "removed all non-english words : [u'good', u'work', u'life', u'mark', u'per']\n",
      " \n",
      "sentence : great place work want great look\n",
      "tokenizer : [u'great', u'place', u'work', u'want', u'great', u'look']\n",
      "stopwords : [u'great', u'place', u'work', u'want', u'great', u'look']\n",
      "removed all non-english words : [u'great', u'place', u'work', u'want', u'great', u'look']\n",
      " \n",
      "sentence : good good work environ good low need perform trade system great work\n",
      "tokenizer : [u'good', u'good', u'work', u'environ', u'good', u'low', u'need', u'perform', u'trade', u'system', u'great', u'work']\n",
      "stopwords : [u'good', u'good', u'work', u'environ', u'good', u'low', u'need', u'perform', u'trade', u'system', u'great', u'work']\n",
      "removed all non-english words : [u'good', u'good', u'work', u'environ', u'good', u'low', u'need', u'perform', u'trade', u'system', u'great', u'work']\n",
      " \n",
      "sentence : best reward\n",
      "tokenizer : [u'best', u'reward']\n",
      "stopwords : [u'best', u'reward']\n",
      "removed all non-english words : [u'best', u'reward']\n",
      " \n",
      "sentence : environ good best cab\n",
      "tokenizer : [u'environ', u'good', u'best', u'cab']\n",
      "stopwords : [u'environ', u'good', u'best', u'cab']\n",
      "removed all non-english words : [u'environ', u'good', u'best', u'cab']\n",
      " \n",
      "pos completed\n",
      "sentence : amp job side worst\n",
      "tokenizer : [u'amp', u'job', u'side', u'worst']\n",
      "stopwords : [u'amp', u'job', u'side', u'worst']\n",
      "removed all non-english words : [u'amp', u'job', u'side', u'worst']\n",
      " \n",
      "sentence : like poor\n",
      "tokenizer : [u'like', u'poor']\n",
      "stopwords : [u'like', u'poor']\n",
      "removed all non-english words : [u'like', u'poor']\n",
      " \n",
      "sentence : bad pay master\n",
      "tokenizer : [u'bad', u'pay', u'master']\n",
      "stopwords : [u'bad', u'pay', u'master']\n",
      "removed all non-english words : [u'bad', u'pay', u'master']\n",
      " \n",
      "sentence : pp rate worst thing lot happen\n",
      "tokenizer : [u'pp', u'rate', u'worst', u'thing', u'lot', u'happen']\n",
      "stopwords : [u'pp', u'rate', u'worst', u'thing', u'lot', u'happen']\n",
      "removed all non-english words : [u'pp', u'rate', u'worst', u'thing', u'lot', u'happen']\n",
      " \n",
      "neg completed\n",
      "sentence : work rd pay roll due would like quit job\n",
      "tokenizer : [u'work', u'rd', u'pay', u'roll', u'due', u'would', u'like', u'quit', u'job']\n",
      "stopwords : [u'work', u'rd', u'pay', u'roll', u'due', u'would', u'like', u'quit', u'job']\n",
      "removed all non-english words : [u'work', u'rd', u'pay', u'roll', u'due', u'would', u'like', u'quit', u'job']\n",
      " \n",
      "sentence : beg pay factor\n",
      "tokenizer : [u'beg', u'pay', u'factor']\n",
      "stopwords : [u'beg', u'pay', u'factor']\n",
      "removed all non-english words : [u'beg', u'pay', u'factor']\n",
      " \n",
      "sentence : grow lower side need support work hour stretch past midnight\n",
      "tokenizer : [u'grow', u'lower', u'side', u'need', u'support', u'work', u'hour', u'stretch', u'past', u'midnight']\n",
      "stopwords : [u'grow', u'lower', u'side', u'need', u'support', u'work', u'hour', u'stretch', u'past', u'midnight']\n",
      "removed all non-english words : [u'grow', u'lower', u'side', u'need', u'support', u'work', u'hour', u'stretch', u'past', u'midnight']\n",
      " \n",
      "sli_neg completed\n"
     ]
    }
   ],
   "source": [
    "preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect7\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n",
      "Aspect1\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n",
      "Aspect4\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n",
      "Aspect5\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n",
      "Aspect3\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n",
      "Aspect6\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n",
      "Aspect2\n",
      "sli_pos completed\n",
      "neutral completed\n",
      "pos completed\n",
      "neg completed\n",
      "sli_neg completed\n"
     ]
    }
   ],
   "source": [
    "dataset=preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for testing preprocess()\n",
    "#sample=preprocess(dataset[196000:200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
