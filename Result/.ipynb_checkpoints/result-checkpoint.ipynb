{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet as w,stopwords \n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import enchant\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading word2vec model\n",
    "model=gensim.models.Word2Vec.load('../Word2Vec_model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialising dictionary, tokenizer, stemmer\n",
    "dictionary = enchant.Dict(\"en_US\")\n",
    "tokenizer=RegexpTokenizer('[a-zA-Z]+')\n",
    "ps=PorterStemmer()\n",
    "all_stopwords=stopwords.words('english')+[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    dataset=[]\n",
    "    for sentence in data:\n",
    "        #print 'sentence'\n",
    "        #print sentence\n",
    "        temp=tokenizer.tokenize(sentence)\n",
    "        #print 'tokenizer'\n",
    "        #print temp\n",
    "        remove_stopword=[word for word in temp if word not in all_stopwords]    # removing stopwords\n",
    "        #print 'stopwords'\n",
    "        #print remove_stopword\n",
    "        #only_english=[ps.stem(word) for word in remove_stopword if dictionary.check(word)== True]  # remove non-english words\n",
    "        only_english=[ps.stem(word) for word in remove_stopword if dictionary.check(word)== True]  # remove non-english words\n",
    "        #print 'removed all non-english words'\n",
    "        #print only_english\n",
    "        if(len(only_english)>1):                  #appends only if length of list >1\n",
    "            dataset.append(' '.join(only_english))\n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading and cleaning dataset\n",
    "def preprocessing(company_name):\n",
    "    dataset=[]\n",
    "    sentences=[]\n",
    "    with open('TestReview/'+company_name+'/review.txt') as f:\n",
    "        reviews=json.load(f)\n",
    "    reviews=np.asarray(reviews)\n",
    "    reviews=np.concatenate(reviews)        #converting it to single list from list of lists\n",
    "    #print 'Reviews'\n",
    "    #print reviews[:10]\n",
    "    for review in reviews:\n",
    "        review=review.lower()             #converting reviews into lowercase\n",
    "        review=review.replace('. ',';')                            \n",
    "        sentences.extend(re.split(' and | but |; | ; |.and ',review))       #splitting criteria\n",
    "    #print 'sentences'\n",
    "    #print sentences[:10]\n",
    "    dataset=preprocess(sentences)\n",
    "    with open('Dataset/'+company_name+'.txt','w') as f:\n",
    "        json.dump(dataset,f)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "[ u' Long working hours and will get very little time for family. Not very process oriented but only end result oriented. They are very competitive and want results at any cost '\n",
      " u\" Mostly it's not so hard but it's too. Boring..And if any buyer than it will be a more  boring ..And even we need to spend our own money ...While just like every job it so. Boring at the beginning..And it become habit...And most important the processing is too slow....... \"\n",
      " u' Good company but turning a little biased towards employees. More focus on hiring IIT grads and also creating huge salary gap between employees. HR policies have improved other than salary normalization. '\n",
      " u' i like electronics work technician then communication skills project work like an embedded and pcb designing networking laptop technician i am fresher searching for job '\n",
      " u' the work there was a lot of fun and and environment really fast paced . we learned a lot of sales tactics in the environment. the target were easy to complete '\n",
      " u\" No Comments, as haven't work with Samsung direct , worked through iEnergizer, average work place, no leaves, less benifits, good environment, try to celebrate occassion. \"\n",
      " u' A lot of knowledge in gadgets..which are releasing into the market....  We will know about everything about the gadget features .a nice company with a full pledged manner.....a lot of good experience '\n",
      " u' To take my job .my typical job Samsung mobiles. Mobiles futures and Mop . Smiling face on to welcome customers.  Peoples are easily coming to on show room to easily. Hartest job in no theft incoming onsite to looking. No the full time employees to happy '\n",
      " u' This job has helped me a lot in gaining the experience about the sales, how to read customers mind and attract them to the new product for the meeting my targets. '\n",
      " u' Samsung Electronics doesnt have a good work life balance but on the hand its salary structure and benefits are really good which compensate for not so good management and not a good work life balance. ']\n",
      "sentences\n",
      "[u' long working hours', u'will get very little time for family;not very process oriented', u'only end result oriented;they are very competitive', u'want results at any cost ', u\" mostly it's not so hard\", u\"it's too;boring.\", u'if any buyer than it will be a more  boring .', u'even we need to spend our own money ...while just like every job it so;boring at the beginning.', u'it become habit..', u'most important the processing is too slow......;']\n"
     ]
    }
   ],
   "source": [
    "#only for printing\n",
    "dataset=preprocessing('Samsung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'long work hour', u'get littl time famili process orient', u'end result orient competit', u'want result cost', u'mostli hard', u'buyer bore', u'even need spend money like everi job bore begin', u'becom habit', u'import process slow', u'good compani']\n"
     ]
    }
   ],
   "source": [
    "#final dataset \n",
    "print dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading vocab\n",
    "with open('../NaiveBayes/vocab_unigram') as f:\n",
    "    vocab=json.load(f)\n",
    "def extract_features(document):       #features are bag of words. document is a list of words of a sentence \n",
    "    features = {}\n",
    "    for word in vocab:\n",
    "        features['contains(%s)' % word] = (word in document)\n",
    "    return features     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_aspect(tokens):            # analyses to which aspect a set of tokens of a sentence belong to\n",
    "    aspect_flags={}\n",
    "    for aspect_name in files:\n",
    "        aspect_flags[aspect_name]=0\n",
    "    for token in tokens:\n",
    "        temp_token=ps.stem(token)\n",
    "        for aspect_name in files:\n",
    "            for aspect in aspects[aspect_name]:\n",
    "                temp_aspect=ps.stem(aspect)\n",
    "                if(temp_token == temp_aspect):\n",
    "                    aspect_flags[aspect_name]=aspect_flags[aspect_name]+1\n",
    "    return aspect_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#naiveBayes\n",
    "def naiveBayes_unigram(company_name):\n",
    "    #loading naivebayes classifier\n",
    "    with open('../NaiveBayes/naive_bayes_unigram_model') as f:\n",
    "        classifier=pickle.load(f)\n",
    "    dataset=preprocessing(company_name)\n",
    "    for sentence in dataset:\n",
    "        print 'sentence->  '+sentence\n",
    "        print 'Polarity= '+classifier.classify(extract_features(sentence.split()))\n",
    "        dist = classifier.prob_classify(extract_features(sentence.split()))\n",
    "        polarity=0\n",
    "        flag=0\n",
    "        for label in dist.samples():\n",
    "            print(\"%s: %f\" % (label, dist.prob(label)))\n",
    "            if(polarity<dist.prob(label)):\n",
    "                polarity=dist.prob(label)\n",
    "                flag=label\n",
    "        if(flag=='neutral'):\n",
    "            polarity=0\n",
    "        elif(flag=='pos'):\n",
    "            polarity=+0.5+(polarity/2)\n",
    "        elif(flag=='neg'):\n",
    "            polarity=-0.5-(polarity/2)    \n",
    "        elif(flag=='sli_pos'):\n",
    "            polarity=polarity/2\n",
    "        elif(flag=='sli_neg'):\n",
    "            polarity=-(polarity/2)   \n",
    "        print 'final polarity='+ str(polarity)\n",
    "        print ' '\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence->  long work hour\n",
      "Polarity= sli_neg\n",
      "neg: 0.007710\n",
      "sli_pos: 0.116827\n",
      "sli_neg: 0.528854\n",
      "neutral: 0.302411\n",
      "pos: 0.044198\n",
      "final polarity=-0.26442699595\n",
      " \n",
      "sentence->  get littl time famili process orient\n",
      "Polarity= neutral\n",
      "neg: 0.002052\n",
      "sli_pos: 0.211779\n",
      "sli_neg: 0.305912\n",
      "neutral: 0.480105\n",
      "pos: 0.000151\n",
      "final polarity=0\n",
      " \n",
      "sentence->  end result orient competit\n",
      "Polarity= neutral\n",
      "neg: 0.001754\n",
      "sli_pos: 0.421355\n",
      "sli_neg: 0.098114\n",
      "neutral: 0.421403\n",
      "pos: 0.057374\n",
      "final polarity=0\n",
      " \n",
      "sentence->  want result cost\n",
      "Polarity= sli_neg\n",
      "neg: 0.069936\n",
      "sli_pos: 0.226345\n",
      "sli_neg: 0.381004\n",
      "neutral: 0.236356\n",
      "pos: 0.086359\n",
      "final polarity=-0.19050206084\n",
      " \n",
      "sentence->  mostli hard\n",
      "Polarity= sli_neg\n",
      "neg: 0.000470\n",
      "sli_pos: 0.135271\n",
      "sli_neg: 0.842939\n",
      "neutral: 0.017992\n",
      "pos: 0.003328\n",
      "final polarity=-0.421469288537\n",
      " \n",
      "sentence->  buyer bore\n",
      "Polarity= neg\n",
      "neg: 0.821084\n",
      "sli_pos: 0.012063\n",
      "sli_neg: 0.145867\n",
      "neutral: 0.020185\n",
      "pos: 0.000801\n",
      "final polarity=-0.910541769869\n",
      " \n",
      "sentence->  even need spend money like everi job bore begin\n",
      "Polarity= sli_neg\n",
      "neg: 0.049290\n",
      "sli_pos: 0.011620\n",
      "sli_neg: 0.937351\n",
      "neutral: 0.001629\n",
      "pos: 0.000110\n",
      "final polarity=-0.468675554996\n",
      " \n",
      "sentence->  becom habit\n",
      "Polarity= sli_pos\n",
      "neg: 0.181575\n",
      "sli_pos: 0.255751\n",
      "sli_neg: 0.207681\n",
      "neutral: 0.252696\n",
      "pos: 0.102297\n",
      "final polarity=0.127875490063\n",
      " \n",
      "sentence->  import process slow\n",
      "Polarity= sli_neg\n",
      "neg: 0.000166\n",
      "sli_pos: 0.328054\n",
      "sli_neg: 0.603052\n",
      "neutral: 0.054402\n",
      "pos: 0.014327\n",
      "final polarity=-0.301526172616\n",
      " \n",
      "sentence->  good compani\n",
      "Polarity= pos\n",
      "neg: 0.000059\n",
      "sli_pos: 0.029096\n",
      "sli_neg: 0.002674\n",
      "neutral: 0.002276\n",
      "pos: 0.965895\n",
      "final polarity=0.982947533291\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#only for printing\n",
    "naiveBayes_unigram('Samsung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
